{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and serving Tensorflow Estimators\n",
    "This notebook shows step by step how to generate input data, train and evaluate a Convolutional Neural Network model, output results, save models, and make predictions using the high-level [Estimator API](https://www.tensorflow.org/guide/estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "BATCH_SIZE = 100                      # number of samples per batch\n",
    "MAX_STEPS = 1000                      # max number of training steps\n",
    "EVAL_STEPS = 1                        # number of steps to run evaluation\n",
    "\n",
    "SAVE_SUMMARY_STEPS = 100              # frequency of summary saving\n",
    "SAVE_CHECKPOINTS_STEPS = 200          # frequency of checkpoint saving - also correspond to evaluation frequency\n",
    "LOGGING_STEPS = 50                    # frequency of logging output\n",
    "\n",
    "MODEL_DIR = '../models/ckpt/'         # save model and checkpoints\n",
    "SAVE_DIR = '../models/pb/'            # save model for TF serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape = (60000, 28, 28)\n",
      "train labels shape = (60000,)\n",
      "evaluation data shape = (10000, 28, 28)\n",
      "evaluation labels shape = (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load training and eval data\n",
    "((train_data, train_labels),\n",
    " (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data/np.float32(255)\n",
    "train_labels = train_labels.astype(np.int32)  # not required\n",
    "\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32)  # not required\n",
    "\n",
    "print('train data shape =', train_data.shape)\n",
    "print('train labels shape =', train_labels.shape)\n",
    "print('evaluation data shape =', eval_data.shape)\n",
    "print('evaluation labels shape =', eval_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Input Data\n",
    "To load data into Estimator `input_fn()` is created through the `tf.data.Dataset.from_tensor_slices` API, which allows to feed numpy arrays into the model function. In this case trainining features are returned by `input_fn()` as a dictionary `{'x': features}`, where `features` is a batch of image numpy arrays, instead of passing directly the array `features` to the model. This is necessary because during serving the serialized input must be in the form `{'key': feature}`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 28, 28) (100,)\n",
      "(100, 28, 28) (100,)\n",
      "(100, 28, 28) (100,)\n",
      "(100, 28, 28) (100,)\n",
      "(100, 28, 28) (100,)\n"
     ]
    }
   ],
   "source": [
    "def input_fn(data, labels, repeat=1):\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "    dataset = dataset.repeat(repeat) # None\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    features, labels = dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    return {'x':features}, labels\n",
    "\n",
    "# verify that the output of input_fn is correct\n",
    "features_batch, labels_batch = input_fn(train_data, train_labels)\n",
    "with tf.Session() as sess:\n",
    "    for i in range(5):\n",
    "        features, labels = sess.run([features_batch, labels_batch]) \n",
    "        print(features['x'].shape, labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During prediction mode the data is not feed in batches but rather as single images/arrays. `predict_input_fn()` assumes that a single array of size 28x28 is to be classified, which needs to be reshape in the same format returned by `input_fn()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "def predict_input_fn(predict_data):\n",
    "    \n",
    "    predict_data = tf.reshape(predict_data, [-1,28,28])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((predict_data))\n",
    "    dataset = dataset.repeat(None)\n",
    "    dataset = dataset.batch(1)\n",
    "    features = dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    return {'x':features}\n",
    "\n",
    "# verify that the output of predict_input_fn is correct\n",
    "predict_data = eval_data[0]        # sample of image to classify\n",
    "features_pred = predict_input_fn(predict_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    feature_pred = sess.run(features_pred)\n",
    "    print(feature_pred['x'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Custom CNN Function\n",
    "The CNN definition is the same as in the official [Tensorflow MNIST example](https://www.tensorflow.org/tutorials/estimators/cnn). Model metrics, such as loss and accuracy, are printed during train and evaluation steps using the `tf.train.LoggingTensorHook` API as described in this [StackOverflow answer](https://stackoverflow.com/questions/45353389/printing-extra-training-metrics-with-tensorflow-estimator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode, params):\n",
    "    \n",
    "    input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=params['dropout_rate'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    predictions = {\"classes\": tf.argmax(input=logits, axis=1), \"probabilities\": tf.nn.softmax(logits)}\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=params['learning_rate'])\n",
    "    \n",
    "    \n",
    "    loss = train_op = eval_metric_ops = None\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        \n",
    "        logging_hook = tf.train.LoggingTensorHook({'predictions': predictions['classes']}, \n",
    "                                                  every_n_iter=LOGGING_STEPS)    \n",
    "    \n",
    "    if (mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL):\n",
    "        \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        \n",
    "        accuracy = tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "        tf.summary.scalar('accuracy', accuracy[1])\n",
    "        eval_metric_ops = {\"accuracy\": accuracy}\n",
    "        \n",
    "        logging_hook = tf.train.LoggingTensorHook({'loss': loss, 'accuracy': accuracy[1]}, \n",
    "                                                  every_n_iter=LOGGING_STEPS)\n",
    "        \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        \n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    estimator_spec = tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op, \n",
    "                                                eval_metric_ops=eval_metric_ops, training_hooks=[logging_hook], \n",
    "                                                prediction_hooks=[logging_hook])\n",
    "        \n",
    "    return estimator_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Estimator\n",
    "The estimator specifications and the train and evaluate routine are defined as in this [StackOverflow answer](https://stackoverflow.com/questions/49619995/how-to-control-when-to-compute-evaluation-vs-training-using-the-estimator-api-of):\n",
    "- the model is trained for a totoal number of steps which is the minumum between `MAX_STEPS`, and the number of steps contained in `repeat` epocs\n",
    "- the evaluation is done at every `SAVE_CHECKPOINTS_STEPS` and for a total of `EVAL_STEPS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '../models/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f402ca61780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "training_config = tf.estimator.RunConfig(\n",
    "    model_dir=MODEL_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS\n",
    ")\n",
    "\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, \n",
    "    config=training_config,\n",
    "    params={\n",
    "        'dropout_rate': 0.4,\n",
    "        'learning_rate': 0.001\n",
    "    }\n",
    ")\n",
    "\n",
    "# repeat = np.floor(MAX_STEPS/(len(train_data)/BATCH_SIZE)).astype(int)\n",
    "repeat = 2\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=lambda:input_fn(train_data, train_labels, repeat=repeat),\n",
    "    max_steps=MAX_STEPS)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=lambda:input_fn(eval_data, eval_labels),\n",
    "    steps=EVAL_STEPS,\n",
    "    name='validation',\n",
    "    start_delay_secs=10,\n",
    "    throttle_secs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate\n",
    "The default output is printed at every `SAVE_SUMMARY_STEPS`, the additional output on the training set is printed at every `LOGGING_STEPS` and on the evaluation set at every `SAVE_CHECKPOINTS_STEPS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 200 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /home/francesco/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-6-396cceb6ab82>:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-396cceb6ab82>:12: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-396cceb6ab82>:24: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-396cceb6ab82>:26: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /home/francesco/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/francesco/.local/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../models/ckpt/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.2990704, step = 1\n",
      "INFO:tensorflow:accuracy = 0.1, loss = 2.2990704\n",
      "INFO:tensorflow:accuracy = 0.1, loss = 2.2982183 (31.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56692\n",
      "INFO:tensorflow:loss = 2.2828856, step = 101 (63.829 sec)\n",
      "INFO:tensorflow:accuracy = 0.11333334, loss = 2.2828856 (32.699 sec)\n",
      "INFO:tensorflow:accuracy = 0.1125, loss = 2.2974088 (31.579 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into ../models/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-01T13:57:18Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/francesco/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../models/ckpt/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-01-13:57:20\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.16, global_step = 200, loss = 2.277221\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: ../models/ckpt/model.ckpt-200\n",
      "INFO:tensorflow:global_step/sec: 1.35961\n",
      "INFO:tensorflow:loss = 2.2869716, step = 201 (73.552 sec)\n",
      "INFO:tensorflow:accuracy = 0.12, loss = 2.2869716 (41.974 sec)\n",
      "INFO:tensorflow:accuracy = 0.12833333, loss = 2.2682366 (30.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53352\n",
      "INFO:tensorflow:loss = 2.268393, step = 301 (65.207 sec)\n",
      "INFO:tensorflow:accuracy = 0.13571429, loss = 2.268393 (35.042 sec)\n",
      "INFO:tensorflow:accuracy = 0.15, loss = 2.2472863 (29.856 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into ../models/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-01T13:59:26Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../models/ckpt/model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-01-13:59:29\n",
      "INFO:tensorflow:Saving dict for global step 400: accuracy = 0.24, global_step = 400, loss = 2.2490828\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400: ../models/ckpt/model.ckpt-400\n",
      "INFO:tensorflow:global_step/sec: 1.58424\n",
      "INFO:tensorflow:loss = 2.2520854, step = 401 (63.120 sec)\n",
      "INFO:tensorflow:accuracy = 0.16, loss = 2.2520854 (33.265 sec)\n",
      "INFO:tensorflow:accuracy = 0.167, loss = 2.247693 (43.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32913\n",
      "INFO:tensorflow:loss = 2.244046, step = 501 (75.232 sec)\n",
      "INFO:tensorflow:accuracy = 0.17, loss = 2.244046 (31.750 sec)\n",
      "INFO:tensorflow:accuracy = 0.18166667, loss = 2.2095091 (32.071 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into ../models/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-01T14:01:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../models/ckpt/model.ckpt-600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-01-14:01:54\n",
      "INFO:tensorflow:Saving dict for global step 600: accuracy = 0.32, global_step = 600, loss = 2.2120352\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 600: ../models/ckpt/model.ckpt-600\n",
      "INFO:tensorflow:global_step/sec: 1.42547\n",
      "INFO:tensorflow:loss = 2.1971545, step = 601 (70.159 sec)\n",
      "INFO:tensorflow:accuracy = 0.19461538, loss = 2.1971545 (38.089 sec)\n",
      "INFO:tensorflow:accuracy = 0.20428571, loss = 2.1909106 (29.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.6269\n",
      "INFO:tensorflow:loss = 2.1856663, step = 701 (61.466 sec)\n",
      "INFO:tensorflow:accuracy = 0.21066667, loss = 2.1856663 (32.335 sec)\n",
      "INFO:tensorflow:accuracy = 0.218125, loss = 2.182043 (38.257 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into ../models/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-01T14:04:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../models/ckpt/model.ckpt-800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-01-14:04:16\n",
      "INFO:tensorflow:Saving dict for global step 800: accuracy = 0.48, global_step = 800, loss = 2.1522868\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 800: ../models/ckpt/model.ckpt-800\n",
      "INFO:tensorflow:global_step/sec: 1.25216\n",
      "INFO:tensorflow:loss = 2.1782072, step = 801 (79.863 sec)\n",
      "INFO:tensorflow:accuracy = 0.22117648, loss = 2.1782072 (41.608 sec)\n",
      "INFO:tensorflow:accuracy = 0.23333333, loss = 2.1198878 (30.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50605\n",
      "INFO:tensorflow:loss = 2.1332378, step = 901 (66.397 sec)\n",
      "INFO:tensorflow:accuracy = 0.24263158, loss = 2.1332378 (35.626 sec)\n",
      "INFO:tensorflow:accuracy = 0.2545, loss = 2.0825322 (26.528 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ../models/ckpt/model.ckpt.\n",
      "WARNING:tensorflow:From /home/francesco/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-01T14:06:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../models/ckpt/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-01-14:06:19\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.63, global_step = 1000, loss = 2.0546615\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ../models/ckpt/model.ckpt-1000\n",
      "INFO:tensorflow:Loss for final step: 2.103045.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.63, 'loss': 2.0546615, 'global_step': 1000}, [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(mnist_classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "A final evaluation is done on the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-01T14:07:38Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../models/ckpt/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-01-14:07:56\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.6089, global_step = 1000, loss = 2.0557766\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ../models/ckpt/model.ckpt-1000\n",
      "{'accuracy': 0.6089, 'loss': 2.0557766, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "eval_results = mnist_classifier.evaluate(input_fn=lambda:input_fn(eval_data, eval_labels))\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction\n",
    "The trained model is used to make a prediction in-session. Note that `predict` return an iterator, therefore the results need to be extraced using `next` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = mnist_classifier.predict(input_fn=lambda:predict_input_fn(eval_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../models/ckpt/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:predictions = [7]\n",
      "{'classes': 7, 'probabilities': array([0.10286731, 0.08767939, 0.09670726, 0.10428555, 0.08617081,\n",
      "       0.08121757, 0.08034296, 0.15033442, 0.09936963, 0.11102506],\n",
      "      dtype=float32)}\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(next(pred_results))\n",
    "print(eval_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Save and Predict\n",
    "The method above rebuild the model graph and restore the model parameters everytime a prediction is called. A more efficient way is firstly to save and export the model, and then to use `predictor` function from `tensorflow.contrib` to output predictions, as explained in [this blog](https://guillaumegenthial.github.io/serving-tensorflow-estimator.html). This approach is particularly suitable for deployement of a tensforlow model [in Flask](https://guillaumegenthial.github.io/serving.html). The exported model requires to define a `serving_receiver_input_fn()` to serialize the input of the prediction function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_receiver_input_fn():\n",
    "    \n",
    "    # serialized tf example - assumes that input_images is a 4-D tensor of shape [batch, height, width, channels]\n",
    "    input_images = tf.placeholder(dtype=tf.float32, shape=[None,None,None,1])\n",
    "    # resize_images needs that the input tensor has the channel dimension\n",
    "    images = tf.image.resize_images(input_images, [28,28])\n",
    "    # dictionary passed to the model \n",
    "    features = {'x': images}\n",
    "    # dictionary of serving input data \n",
    "    receiver_tensors = {'x': input_images}\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /home/francesco/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from ../models/ckpt/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ../models/pb/temp-b'1554128599'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'../models/pb/1554128599'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_classifier.export_savedmodel(SAVE_DIR, serving_input_receiver_fn=serving_receiver_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look cleverly for the last saved model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/francesco/.local/lib/python3.6/site-packages/tensorflow/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from ../models/pb/1554128599/variables/variables\n"
     ]
    }
   ],
   "source": [
    "subdirs = [x for x in Path(SAVE_DIR).iterdir() if x.is_dir() and 'temp' not in str(x)]\n",
    "latest_dir = str(sorted(subdirs)[-1])\n",
    "predict_fn = predictor.from_saved_model(latest_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that now the predictions are faster to be computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [7 0]\n",
      "true labels [7 2]\n"
     ]
    }
   ],
   "source": [
    "# serving images needs to be of shape [batch, height, width, channels]\n",
    "serving_examples = eval_data[0:2].reshape(-1,28,28,1)\n",
    "predictions = predict_fn({'x': serving_examples})\n",
    "print('predictions', predictions['classes'])\n",
    "print('true labels', eval_labels[0:2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
