{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "N_STEPS = 1000\n",
    "N_SAVE = 200 # seems to regulate also tensorboard outputs frequency and evaluation frequency. need to investigate\n",
    "MODEL_DIR = '../models/ckpt/' # save model and checkpoints\n",
    "SAVED_DIR = '../models/pb/' # save model for TF serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape = (60000, 28, 28)\n",
      "train labels shape = (60000,)\n",
      "evaluation data shape = (10000, 28, 28)\n",
      "evaluation labels shape = (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load training and eval data\n",
    "((train_data, train_labels),\n",
    " (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data/np.float32(255)\n",
    "train_labels = train_labels.astype(np.int32)  # not required\n",
    "\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32)  # not required\n",
    "\n",
    "print('train data shape =', train_data.shape)\n",
    "print('train labels shape =', train_labels.shape)\n",
    "print('evaluation data shape =', eval_data.shape)\n",
    "print('evaluation labels shape =', eval_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Input Data\n",
    "### 1. Using tf.estimators.inputs.numpy_input_fn API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#     x={\"x\": train_data},\n",
    "#     y=train_labels,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     num_epochs=None,\n",
    "#     shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through input data queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# features_op, labels_op = train_input_fn()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "        \n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "#     for i in range(5):\n",
    "#         feature_batch, label_batch = sess.run([features_op, labels_op])\n",
    "#         print(feature_batch['x'].shape, label_batch.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using tf.data.Dataset API\n",
    "`train_input_fn()` is created through tf.data.Dataset API as this is the preferred way to iterate through input dataset pipelines. Note also that this method does not require to define training data as a dictionary of features, but instead allows to pass directly arrays of images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "    # train: None and set N_STEPS\n",
    "    # train and evaluate: define with repeat and max_steps. Repeat=1 and BATCH_SIZE=100 gives 600 training steps\n",
    "    dataset = dataset.repeat(1) # None\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    features, labels = dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 28, 28) (100,)\n",
      "(100, 28, 28) (100,)\n",
      "(100, 28, 28) (100,)\n",
      "(100, 28, 28) (100,)\n",
      "(100, 28, 28) (100,)\n"
     ]
    }
   ],
   "source": [
    "features_op, labels_op = train_input_fn()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(5):\n",
    "        feature_batch, label_batch = sess.run([features_op, labels_op])\n",
    "        print(feature_batch.shape, label_batch.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn():\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eval_data, eval_labels))\n",
    "    dataset = dataset.repeat(1)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    features, labels = dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_input_fn(predict_data):\n",
    "    \n",
    "    predict_data = tf.reshape(predict_data, [-1,28,28])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((predict_data))\n",
    "    dataset = dataset.repeat(None)\n",
    "    dataset = dataset.batch(1)\n",
    "    features = dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "predict_data = eval_data[0]\n",
    "features_pred = predict_input_fn(predict_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    feature_pred = sess.run(features_pred)\n",
    "    print(feature_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Custom DNN Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode, params):\n",
    "    \n",
    "    input_layer = tf.reshape(features, [-1, 28, 28, 1])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=params['dropout_rate'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    predictions = {\"classes\": tf.argmax(input=logits, axis=1), \"probabilities\": tf.nn.softmax(logits)}\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=params['learning_rate'])\n",
    "    \n",
    "    \n",
    "    loss = train_op = eval_metric_ops = None\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        \n",
    "        logging_hook = tf.train.LoggingTensorHook({'predictions': predictions}, every_n_iter=10)    \n",
    "    \n",
    "    if (mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL):\n",
    "        \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        \n",
    "        accuracy = tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "        tf.summary.scalar('accuracy', accuracy[1])\n",
    "        eval_metric_ops = {\"accuracy\": accuracy}\n",
    "        \n",
    "        logging_hook = tf.train.LoggingTensorHook({'loss': loss, 'accuracy': accuracy[1]}, every_n_iter=10)\n",
    "        \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        \n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    estimator_spec = tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op, \n",
    "                                                eval_metric_ops=eval_metric_ops, training_hooks=[logging_hook], \n",
    "                                                prediction_hooks=[logging_hook])\n",
    "        \n",
    "    return estimator_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '../models/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f79d9ecc978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "training_config = tf.estimator.RunConfig(\n",
    "    model_dir=MODEL_DIR,\n",
    "    save_summary_steps=N_SAVE,\n",
    "    save_checkpoints_steps=N_SAVE)\n",
    "\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, \n",
    "    model_dir=MODEL_DIR,\n",
    "    config=training_config,\n",
    "    params={\n",
    "        'dropout_rate': 0.4,\n",
    "        'learning_rate': 0.001\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train\n",
    "# mnist_classifier.train(\n",
    "#     input_fn=train_input_fn,\n",
    "#     steps=N_STEPS\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:start experiment...\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 200 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /home/francesco/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-11-432d4eb02981>:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-11-432d4eb02981>:12: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-11-432d4eb02981>:24: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-11-432d4eb02981>:26: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /home/francesco/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/francesco/.local/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../models/ckpt/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3025591, step = 1\n",
      "INFO:tensorflow:accuracy = 0.07, loss = 2.3025591\n",
      "INFO:tensorflow:accuracy = 0.075, loss = 2.2954888 (6.072 sec)\n",
      "INFO:tensorflow:accuracy = 0.08, loss = 2.3114016 (4.569 sec)\n",
      "INFO:tensorflow:accuracy = 0.075, loss = 2.3124144 (5.365 sec)\n",
      "INFO:tensorflow:accuracy = 0.08, loss = 2.305607 (4.463 sec)\n",
      "INFO:tensorflow:accuracy = 0.08833333, loss = 2.3014867 (4.270 sec)\n",
      "INFO:tensorflow:accuracy = 0.09714286, loss = 2.303859 (4.521 sec)\n",
      "INFO:tensorflow:accuracy = 0.10375, loss = 2.2909822 (4.780 sec)\n",
      "INFO:tensorflow:accuracy = 0.10555556, loss = 2.3049407 (4.735 sec)\n",
      "INFO:tensorflow:accuracy = 0.113, loss = 2.2785647 (4.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.08632\n",
      "INFO:tensorflow:loss = 2.2838778, step = 101 (47.921 sec)\n",
      "INFO:tensorflow:accuracy = 0.12090909, loss = 2.2838778 (4.829 sec)\n",
      "INFO:tensorflow:accuracy = 0.123333335, loss = 2.2734237 (4.559 sec)\n",
      "INFO:tensorflow:accuracy = 0.122307695, loss = 2.28332 (4.479 sec)\n",
      "INFO:tensorflow:accuracy = 0.12428571, loss = 2.2812753 (4.564 sec)\n",
      "INFO:tensorflow:accuracy = 0.132, loss = 2.2586522 (4.472 sec)\n",
      "INFO:tensorflow:accuracy = 0.139375, loss = 2.26379 (4.193 sec)\n",
      "INFO:tensorflow:accuracy = 0.1382353, loss = 2.2841566 (4.870 sec)\n",
      "INFO:tensorflow:accuracy = 0.14388889, loss = 2.270856 (4.983 sec)\n",
      "INFO:tensorflow:accuracy = 0.14526317, loss = 2.267508 (5.232 sec)\n",
      "INFO:tensorflow:accuracy = 0.1505, loss = 2.2573655 (4.923 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into ../models/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-20T14:27:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/francesco/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../models/ckpt/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-20-14:27:29\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.317, global_step = 200, loss = 2.262825\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: ../models/ckpt/model.ckpt-200\n",
      "INFO:tensorflow:global_step/sec: 1.75897\n",
      "INFO:tensorflow:loss = 2.276494, step = 201 (56.848 sec)\n",
      "INFO:tensorflow:accuracy = 0.15095238, loss = 2.276494 (14.578 sec)\n",
      "INFO:tensorflow:accuracy = 0.15363637, loss = 2.2679412 (5.248 sec)\n",
      "INFO:tensorflow:accuracy = 0.15434782, loss = 2.2621665 (4.770 sec)\n",
      "INFO:tensorflow:accuracy = 0.15916666, loss = 2.2530875 (5.134 sec)\n",
      "INFO:tensorflow:accuracy = 0.1644, loss = 2.2466593 (7.954 sec)\n",
      "INFO:tensorflow:accuracy = 0.17269231, loss = 2.239584 (5.596 sec)\n",
      "INFO:tensorflow:accuracy = 0.17740741, loss = 2.2361844 (7.748 sec)\n",
      "INFO:tensorflow:accuracy = 0.17892857, loss = 2.2539191 (5.117 sec)\n",
      "INFO:tensorflow:accuracy = 0.18551724, loss = 2.2145715 (8.162 sec)\n",
      "INFO:tensorflow:accuracy = 0.18766667, loss = 2.2453501 (4.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.69346\n",
      "INFO:tensorflow:loss = 2.2420146, step = 301 (59.052 sec)\n",
      "INFO:tensorflow:accuracy = 0.19032258, loss = 2.2420146 (5.214 sec)\n",
      "INFO:tensorflow:accuracy = 0.193125, loss = 2.2491608 (6.152 sec)\n",
      "INFO:tensorflow:accuracy = 0.19515151, loss = 2.2367623 (5.973 sec)\n",
      "INFO:tensorflow:accuracy = 0.19647059, loss = 2.2264485 (8.178 sec)\n",
      "INFO:tensorflow:accuracy = 0.20028572, loss = 2.2170267 (4.489 sec)\n",
      "INFO:tensorflow:accuracy = 0.20277777, loss = 2.2259603 (5.327 sec)\n",
      "INFO:tensorflow:accuracy = 0.2045946, loss = 2.2411354 (6.134 sec)\n",
      "INFO:tensorflow:accuracy = 0.20710526, loss = 2.2321587 (4.712 sec)\n",
      "INFO:tensorflow:accuracy = 0.21179487, loss = 2.2226303 (4.779 sec)\n",
      "INFO:tensorflow:accuracy = 0.21775, loss = 2.1969922 (8.546 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into ../models/ckpt/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-20T14:29:39Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../models/ckpt/model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-20-14:29:45\n",
      "INFO:tensorflow:Saving dict for global step 400: accuracy = 0.489, global_step = 400, loss = 2.2132692\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400: ../models/ckpt/model.ckpt-400\n",
      "INFO:tensorflow:global_step/sec: 1.30643\n",
      "INFO:tensorflow:loss = 2.203748, step = 401 (76.542 sec)\n",
      "INFO:tensorflow:accuracy = 0.22121951, loss = 2.203748 (22.249 sec)\n",
      "INFO:tensorflow:accuracy = 0.22380953, loss = 2.2208004 (5.195 sec)\n",
      "INFO:tensorflow:accuracy = 0.22674419, loss = 2.1997023 (5.927 sec)\n",
      "INFO:tensorflow:accuracy = 0.22909091, loss = 2.2186337 (7.621 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:accuracy = 0.23222223, loss = 2.1995754 (7.684 sec)\n",
      "INFO:tensorflow:accuracy = 0.23434782, loss = 2.2108128 (5.363 sec)\n",
      "INFO:tensorflow:accuracy = 0.23638298, loss = 2.2135553 (7.157 sec)\n",
      "INFO:tensorflow:accuracy = 0.24, loss = 2.176304 (5.619 sec)\n",
      "INFO:tensorflow:accuracy = 0.24163266, loss = 2.1869352 (6.796 sec)\n",
      "INFO:tensorflow:accuracy = 0.2444, loss = 2.193007 (6.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54858\n",
      "INFO:tensorflow:loss = 2.1871564, step = 501 (64.577 sec)\n",
      "INFO:tensorflow:accuracy = 0.24725491, loss = 2.1871564 (6.486 sec)\n",
      "INFO:tensorflow:accuracy = 0.25230768, loss = 2.1566398 (6.183 sec)\n"
     ]
    }
   ],
   "source": [
    "train_spec = tf.estimator.TrainSpec(\n",
    "    train_input_fn,\n",
    "    max_steps=1000)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    eval_input_fn,\n",
    "    steps=10,# number of steps for which evaluate the model\n",
    "    name='validation',\n",
    "    start_delay_secs=10,\n",
    "    throttle_secs=20)\n",
    "\n",
    "tf.logging.info('start experiment...')\n",
    "tf.estimator.train_and_evaluate(mnist_classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = mnist_classifier.predict(input_fn=lambda:predict_input_fn(eval_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(pred_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
